{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP09sir9pkXLgVJeugGcezd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lpoggetto/fiap_liveness/blob/main/trabalho_computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# limpando a pasta\n",
        "!rm -rf /content/*"
      ],
      "metadata": {
        "id": "XKMUclRKudSG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # instalando pacotes utilizados\n",
        "\n",
        "!pip install git+https://github.com/hukkelas/DSFD-Pytorch-Inference.git\n",
        "!pip install face_detection\n",
        "!pip install mediapipe\n",
        "!pip install dlib\n",
        "\n",
        "print('pacotes instalados')"
      ],
      "metadata": {
        "id": "LkvgAJsEWUCV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52855d24-7139-4e76-c041-5393f6a2c2df"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/hukkelas/DSFD-Pytorch-Inference.git\n",
            "  Cloning https://github.com/hukkelas/DSFD-Pytorch-Inference.git to /tmp/pip-req-build-8uxnb8gb\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/hukkelas/DSFD-Pytorch-Inference.git /tmp/pip-req-build-8uxnb8gb\n",
            "  Resolved https://github.com/hukkelas/DSFD-Pytorch-Inference.git to commit dde9c7dd9cdc9254c2ca345222c86a8ecfa17f5b\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_detection==0.2.1) (1.26.4)\n",
            "Requirement already satisfied: face_detection in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_detection) (1.26.4)\n",
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.10/dist-packages (0.10.20)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.8.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.5)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.10/dist-packages (19.24.2)\n",
            "pacotes instalados\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importando os pacotes utilizados"
      ],
      "metadata": {
        "id": "dHymk3FauK4t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eDA1up8gsJma"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import bz2\n",
        "import os\n",
        "import face_detection\n",
        "import mediapipe as mp\n",
        "from scipy.spatial import distance as dist\n",
        "import dlib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#Exibição na mesma tela do Jupyter\n",
        "%matplotlib inline\n",
        "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
        "\n",
        "# pacotes utilizados para tirar foto/videos\n",
        "from IPython.display import display, Javascript, Image, HTML\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import threading\n",
        "\n",
        "dlib.DLIB_USE_CUDA = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# modelo pre-treinado dos landmarks usados no dlib\n",
        "url = \"http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\"\n",
        "file_name = \"shape_predictor_68_face_landmarks.dat.bz2\"\n",
        "\n",
        "# criando diretorio para salvar o modelo\n",
        "os.makedirs('dlib_models', exist_ok=True)\n",
        "\n",
        "# apontando para o diretorio\n",
        "os.chdir('dlib_models')\n",
        "\n",
        "# baixando o arquivo se já nao estiver baixado\n",
        "if not os.path.exists(file_name):\n",
        "  !wget {url}\n",
        "\n",
        "# extraindo o arquivo.dat se ja nao estiver extraido\n",
        "dat_file = \"shape_predictor_68_face_landmarks.dat\"\n",
        "if not os.path.exists(dat_file):\n",
        "  with bz2.BZ2File(file_name, \"rb\") as f_in, open(dat_file, \"wb\") as f_out:\n",
        "    f_out.write(f_in.read())\n",
        "\n",
        "# apagando o bz2 (compactado)\n",
        "os.remove(file_name)\n",
        "\n",
        "# voltando para o diretorio original\n",
        "os.chdir('..')\n",
        "\n",
        "print('modelo baixado')"
      ],
      "metadata": {
        "id": "ptCQRHaKFEui",
        "outputId": "cf37ca07-05b5-4b82-d5a7-b8689578b3c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-03 14:51:04--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  61.07M  78.4MB/s    in 0.8s    \n",
            "\n",
            "2025-01-03 14:51:05 (78.4 MB/s) - ‘shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n",
            "modelo baixado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# JavaScript code to capture video\n",
        "html_code = \"\"\"\n",
        "<video id=\"video\" width=\"640\" height=\"480\" autoplay></video>\n",
        "<button id=\"startButton\">Start Recording</button>\n",
        "<button id=\"stopButton\" disabled>Stop Recording</button>\n",
        "<video id=\"playback\" width=\"640\" height=\"480\" controls></video>\n",
        "<a id=\"downloadLink\" download=\"recorded-video.webm\"></a>\n",
        "\n",
        "<script>\n",
        "    const video = document.querySelector('#video');\n",
        "    const playback = document.querySelector('#playback');\n",
        "    const downloadLink = document.querySelector('#downloadLink');\n",
        "    const startButton = document.querySelector('#startButton');\n",
        "    const stopButton = document.querySelector('#stopButton');\n",
        "\n",
        "    navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {\n",
        "        video.srcObject = stream;\n",
        "        let mediaRecorder;\n",
        "        const chunks = [];\n",
        "\n",
        "        startButton.onclick = () => {\n",
        "            mediaRecorder = new MediaRecorder(stream);\n",
        "            mediaRecorder.start();\n",
        "            startButton.disabled = true;\n",
        "            stopButton.disabled = false;\n",
        "\n",
        "            mediaRecorder.ondataavailable = (event) => chunks.push(event.data);\n",
        "            mediaRecorder.onstop = () => {\n",
        "                const blob = new Blob(chunks, { type: 'video/webm' });\n",
        "                playback.src = URL.createObjectURL(blob);\n",
        "                downloadLink.href = playback.src;\n",
        "                downloadLink.textContent = 'Download Video';\n",
        "                startButton.disabled = false;\n",
        "                stopButton.disabled = true;\n",
        "            };\n",
        "        };\n",
        "\n",
        "        stopButton.onclick = () => mediaRecorder.stop();\n",
        "    });\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "# Display the HTML interface\n",
        "display(HTML(html_code))"
      ],
      "metadata": {
        "id": "UR6wrfItjxqb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criando pasta para colocar o video gravado\n",
        "os.makedirs('videos', exist_ok=True)"
      ],
      "metadata": {
        "id": "w0z97fyyQnUc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Montando detector de faces\n",
        "\n",
        "Utilizando o algoritmo DSFDDetector para detectar uma face"
      ],
      "metadata": {
        "id": "ANvOYVy9WL0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculo_distancia_olhos(eye):\n",
        "    # Calcula a distância euclidiana entre os pontos dos olhos\n",
        "    A = dist.euclidean(eye[1], eye[5])\n",
        "    B = dist.euclidean(eye[2], eye[4])\n",
        "    C = dist.euclidean(eye[0], eye[3])\n",
        "    # Calcula a razão de aspecto do olho\n",
        "    ear = (A + B) / (2.0 * C)\n",
        "    return ear\n",
        "\n",
        "def detector_faces_video(video_path, output_path, threshhold_ear=0.3):\n",
        "    # Criando o detector de faces\n",
        "    detector = face_detection.build_detector(\n",
        "        \"DSFDDetector\",\n",
        "        confidence_threshold=0.5,\n",
        "        nms_iou_threshold=0.3\n",
        "    )\n",
        "    # utilizando algoritmo de 68 pontos faciais\n",
        "    preditor_marcos_faciais = dlib.shape_predictor(\n",
        "        '/content/dlib_models/shape_predictor_68_face_landmarks.dat'\n",
        "        )\n",
        "\n",
        "    # abrindo o arquivo de video\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "\n",
        "    fps = video.get(cv2.CAP_PROP_FPS)  # Get the original frame rate\n",
        "    if fps == 0 or fps is None:  # Fallback if FPS is not retrieved correctly\n",
        "      fps = 30  # Default to 30 FPS (you can adjust this if needed)\n",
        "\n",
        "\n",
        "    # propriedades do video\n",
        "    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'VP80')  # WebM codec\n",
        "    out = cv2.VideoWriter(output_path, fourcc, 15, (width, height))\n",
        "\n",
        "    while True:\n",
        "        ret, frame = video.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # convertendo para RGB\n",
        "        rgb_frame = frame[:, :, ::-1]\n",
        "\n",
        "        # detectando  face\n",
        "        detections = detector.detect(rgb_frame)\n",
        "\n",
        "        # desenhando o retangulo na face\n",
        "        for det in detections:\n",
        "            x1, y1, x2, y2, score = det\n",
        "            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
        "\n",
        "            # Draw a red rectangle by default\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "\n",
        "            # utilizando dlib para detectar a face\n",
        "            dlib_rect = dlib.rectangle(x1,y1,x2,y2)\n",
        "\n",
        "            # marcos faciais\n",
        "            landmarks = preditor_marcos_faciais(rgb_frame, dlib_rect)\n",
        "\n",
        "            # coordenadas dos olhos\n",
        "            left_eye = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(36, 42)]\n",
        "            right_eye = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(42, 48)]\n",
        "\n",
        "            # calculando a distancia para ambos os olhos\n",
        "            olho_esq = calculo_distancia_olhos(left_eye)\n",
        "            olho_dir = calculo_distancia_olhos(right_eye)\n",
        "            ear = (olho_esq + olho_dir) / 2\n",
        "\n",
        "            # validacao de olhos piscando\n",
        "            blink_detected = ear < threshhold_ear\n",
        "\n",
        "            # Check if blink is detected\n",
        "            if ear < threshhold_ear:\n",
        "                # Update the rectangle to green if liveness is proven\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                cv2.putText(frame, 'Liveness OK', (x1, y1 - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "        # retorno do video\n",
        "        out.write(frame)\n",
        "\n",
        "    # Release resources\n",
        "    video.release()\n",
        "    out.release()\n",
        "    print(f\"Input video FPS: {fps}\")\n",
        "    print(f\"Processed video saved to: {output_path}\")\n",
        "\n",
        "# Example usage\n",
        "input_video_path = '/content/videos/recorded-video.webm'\n",
        "output_video_path = '/content/videos/recorded-video_processado.webm'\n",
        "\n",
        "# chamada da funcao criada anteriormente\n",
        "detector_faces_video(input_video_path, output_video_path, threshhold_ear = 0.3)"
      ],
      "metadata": {
        "id": "tCX9NZJRZS6k",
        "outputId": "de960a31-c97a-4b6b-d9c3-2ebfbdfa81b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input video FPS: 62.5\n",
            "Processed video saved to: /content/videos/recorded-video_processado.webm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sj3_H-hSuvxk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}